{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# on server: 'screen' ,then start script\n",
    "# use 'strg+a d' to return to terminal\n",
    "# use 'screen -r' to return to screen\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers\n",
    "from keras.layers import recurrent\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.utils import plot_model\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn parameters\n",
    "RNN = recurrent.LSTM\n",
    "SENT_HIDDEN_SIZE = 100 #100 is the standard\n",
    "QUERY_HIDDEN_SIZE = 100 #100 is the standard\n",
    "BATCH_SIZE = 512 #for the training on the GPU this to be has to very large, otherwise the GPU is used very inefficiently\n",
    "EPOCHS = 100\n",
    "\n",
    "#glove embedding parameters\n",
    "GLOVE_DIR = '../glove/glove.6B.100d.txt'\n",
    "EMBEDDING_DIM = 100\n",
    "EVAL_SPLIT = 0.2 \n",
    "\n",
    "#\n",
    "path='models/baseline_biderec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open SQuAD-dataset and extract the relevant data from the json-file\n",
    "#to a easier readable/accessible dictionary\n",
    "with open('SQuAD/train-v2.0.json') as file:\n",
    "    train=json.load(file)\n",
    "train_context=[]\n",
    "train_question=[]\n",
    "train_answer=[]\n",
    "train_new={'context':train_context,'question':train_question,'answer':train_answer}\n",
    "for j,data in enumerate(train['data']):\n",
    "    for i,paragraph in enumerate(data['paragraphs']):\n",
    "        context=paragraph['context']\n",
    "        for qas in paragraph['qas']:\n",
    "            #create a dataset with only the answerable questions\n",
    "            if (qas['is_impossible']==False):\n",
    "                train_new['context'].append(context)\n",
    "                train_new['question'].append(qas['question'])\n",
    "                train_new['answer'].append(qas['answers'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the data in one vector for preprocessing\n",
    "train_all=[]\n",
    "for line in train_new['context']:\n",
    "    train_all.append(line)\n",
    "for line in train_new['question']:\n",
    "    train_all.append(line)\n",
    "for line in train_new['answer']:\n",
    "    train_all.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91925,)\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for text in train_all:\n",
    "    vocab |= set(text_to_word_sequence(text))\n",
    "vocab = sorted(vocab)\n",
    "vocab_size = len(vocab) + 1\n",
    "print(np.shape(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 91925 unique tokens.\n",
      "Shape of context tensor: (86821, 675)\n",
      "Shape of question tensor: (86821, 40)\n",
      "Shape of answer tensor: (86821, 43)\n"
     ]
    }
   ],
   "source": [
    "#prepare the data to use as input of the rnn\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(train_all)\n",
    "context_sequences = tokenizer.texts_to_sequences(train_new['context'])\n",
    "question_sequences = tokenizer.texts_to_sequences(train_new['question'])\n",
    "answer_sequences = tokenizer.texts_to_sequences(train_new['answer'])\n",
    "\n",
    "max_len_context=max(map(len,context_sequences))\n",
    "max_len_question=max(map(len,question_sequences))\n",
    "max_len_answer=max(map(len,answer_sequences))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "context = pad_sequences(context_sequences, maxlen=max_len_context)\n",
    "question = pad_sequences(question_sequences, maxlen=max_len_question)\n",
    "answer = pad_sequences(answer_sequences, maxlen=max_len_answer)\n",
    "\n",
    "print('Shape of context tensor:', context.shape)\n",
    "print('Shape of question tensor:', question.shape)\n",
    "print('Shape of answer tensor:', answer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training set and an evaluation set\n",
    "indices = np.arange(context.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "context = context[indices]\n",
    "question = question[indices]\n",
    "answer = answer[indices]\n",
    "num_eval_samples = int(EVAL_SPLIT * context.shape[0])\n",
    "\n",
    "x_train_context = context[:-num_eval_samples]\n",
    "x_train_question = question[:-num_eval_samples]\n",
    "y_train_answer = answer[:-num_eval_samples]\n",
    "\n",
    "x_eval_context = context[-num_eval_samples:]\n",
    "x_eval_question = question[-num_eval_samples:]\n",
    "y_eval_answer = answer[-num_eval_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#FIX_ME: add glove download\n",
    "# https://nlp.stanford.edu/projects/glove/\n",
    "#get glove embeddings\n",
    "embeddings_index = {}\n",
    "f = open(GLOVE_DIR)#os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the glove-embedding to a matrix\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create non-trainable embedding layers\n",
    "# for the context and the question each\n",
    "context_embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_len_context,\n",
    "                            trainable=False,\n",
    "                            name='context_embedding')\n",
    "question_embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_len_question,\n",
    "                            trainable=False,\n",
    "                            name='question_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "successfully built the model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Context_input (InputLayer)      (None, 675)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Question_input (InputLayer)     (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "context_embedding (Embedding)   (None, 675, 100)     9192600     Context_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "question_embedding (Embedding)  (None, 40, 100)      9192600     Question_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 200)          160800      context_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 200)          160800      question_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 400)          0           bidirectional_1[0][0]            \n",
      "                                                                 bidirectional_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 43)           17243       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 18,724,043\n",
      "Trainable params: 338,843\n",
      "Non-trainable params: 18,385,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "context_layer = layers.Input(shape=(max_len_context,), dtype='int32',name='Context_input')\n",
    "encoded_context = context_embedding_layer(context_layer)\n",
    "encoded_context = Bidirectional(LSTM(SENT_HIDDEN_SIZE))(encoded_context)\n",
    "\n",
    "question_layer = layers.Input(shape=(max_len_question,), dtype='int32',name='Question_input')\n",
    "encoded_question = question_embedding_layer(question_layer)\n",
    "encoded_question = Bidirectional(LSTM(QUERY_HIDDEN_SIZE))(encoded_question)\n",
    "\n",
    "merged = layers.concatenate([encoded_context, encoded_question])\n",
    "preds = layers.Dense(max_len_answer, activation='softmax')(merged) #dimensions of dense layer have to to the same as the answer dimensions\n",
    "\n",
    "model = Model([context_layer, question_layer], preds)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print('successfully built the model')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"337pt\" viewBox=\"0.00 0.00 564.00 337.00\" width=\"564pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 333)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-333 560,-333 560,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140153852277984 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140153852277984</title>\n",
       "<polygon fill=\"none\" points=\"54,-292.5 54,-328.5 215,-328.5 215,-292.5 54,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-306.8\">Context_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140154142232760 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140154142232760</title>\n",
       "<polygon fill=\"none\" points=\"37.5,-219.5 37.5,-255.5 231.5,-255.5 231.5,-219.5 37.5,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-233.8\">context_embedding: Embedding</text>\n",
       "</g>\n",
       "<!-- 140153852277984&#45;&gt;140154142232760 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140153852277984-&gt;140154142232760</title>\n",
       "<path d=\"M134.5,-292.4551C134.5,-284.3828 134.5,-274.6764 134.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"138.0001,-265.5903 134.5,-255.5904 131.0001,-265.5904 138.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140153852278208 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140153852278208</title>\n",
       "<polygon fill=\"none\" points=\"338,-292.5 338,-328.5 505,-328.5 505,-292.5 338,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421.5\" y=\"-306.8\">Question_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140153852226752 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140153852226752</title>\n",
       "<polygon fill=\"none\" points=\"321.5,-219.5 321.5,-255.5 521.5,-255.5 521.5,-219.5 321.5,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421.5\" y=\"-233.8\">question_embedding: Embedding</text>\n",
       "</g>\n",
       "<!-- 140153852278208&#45;&gt;140153852226752 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140153852278208-&gt;140153852226752</title>\n",
       "<path d=\"M421.5,-292.4551C421.5,-284.3828 421.5,-274.6764 421.5,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"425.0001,-265.5903 421.5,-255.5904 418.0001,-265.5904 425.0001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140153852279328 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140153852279328</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 269,-182.5 269,-146.5 0,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"134.5\" y=\"-160.8\">bidirectional_1(lstm_1): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 140154142232760&#45;&gt;140153852279328 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140154142232760-&gt;140153852279328</title>\n",
       "<path d=\"M134.5,-219.4551C134.5,-211.3828 134.5,-201.6764 134.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"138.0001,-192.5903 134.5,-182.5904 131.0001,-192.5904 138.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140153698848608 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140153698848608</title>\n",
       "<polygon fill=\"none\" points=\"287,-146.5 287,-182.5 556,-182.5 556,-146.5 287,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"421.5\" y=\"-160.8\">bidirectional_2(lstm_2): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 140153852226752&#45;&gt;140153698848608 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140153852226752-&gt;140153698848608</title>\n",
       "<path d=\"M421.5,-219.4551C421.5,-211.3828 421.5,-201.6764 421.5,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"425.0001,-192.5903 421.5,-182.5904 418.0001,-192.5904 425.0001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140153852382008 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140153852382008</title>\n",
       "<polygon fill=\"none\" points=\"193.5,-73.5 193.5,-109.5 361.5,-109.5 361.5,-73.5 193.5,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-87.8\">concatenate_1: Concatenate</text>\n",
       "</g>\n",
       "<!-- 140153852279328&#45;&gt;140153852382008 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140153852279328-&gt;140153852382008</title>\n",
       "<path d=\"M169.8483,-146.4551C188.9267,-136.7157 212.6652,-124.5975 232.9923,-114.2207\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"234.7475,-117.2544 242.0627,-109.5904 231.5647,-111.0198 234.7475,-117.2544\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140153698848608&#45;&gt;140153852382008 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140153698848608-&gt;140153852382008</title>\n",
       "<path d=\"M385.9045,-146.4551C366.6927,-136.7157 342.7882,-124.5975 322.3189,-114.2207\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"323.687,-110.9903 313.1851,-109.5904 320.5219,-117.2338 323.687,-110.9903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140153443330592 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140153443330592</title>\n",
       "<polygon fill=\"none\" points=\"226.5,-.5 226.5,-36.5 328.5,-36.5 328.5,-.5 226.5,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"277.5\" y=\"-14.8\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 140153852382008&#45;&gt;140153443330592 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140153852382008-&gt;140153443330592</title>\n",
       "<path d=\"M277.5,-73.4551C277.5,-65.3828 277.5,-55.6764 277.5,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"281.0001,-46.5903 277.5,-36.5904 274.0001,-46.5904 281.0001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Training')\n",
    "# model.fit([x_train_context, x_train_question], y_train_answer,\n",
    "#           batch_size=BATCH_SIZE,\n",
    "#           epochs=EPOCHS,\n",
    "#           validation_split=0.05)\n",
    "\n",
    "# print('Evaluation')\n",
    "# loss, acc = model.evaluate([x_eval_context, x_eval_question], y_eval_answer,\n",
    "#                            batch_size=BATCH_SIZE)\n",
    "# print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save model\n"
     ]
    }
   ],
   "source": [
    "print('save model')\n",
    "plot_model(model, to_file=path+'/model.png')\n",
    "model.save_weights('models/baseline/baseline_model.h5') #save weights\n",
    "model_json = model.to_json()\n",
    "with open(\"models/baseline/baseline_model.json\",'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
