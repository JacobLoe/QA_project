{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# on server: 'screen' ,then start script\n",
    "# use 'strg+a d' to return to terminal\n",
    "# use 'screen -r' to return to screen\n",
    "\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras import layers\n",
    "from keras.layers import recurrent\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.text import text_to_word_sequence\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Bidirectional\n",
    "from keras.utils import plot_model\n",
    "# os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn parameters\n",
    "RNN = recurrent.LSTM\n",
    "SENT_HIDDEN_SIZE = 100 #100 is the standard\n",
    "QUERY_HIDDEN_SIZE = 100 #100 is the standard\n",
    "BATCH_SIZE = 512 #for the training on the GPU this to be has to very large, otherwise the GPU is used very inefficiently\n",
    "EPOCHS = 100\n",
    "\n",
    "#glove embedding parameters\n",
    "GLOVE_DIR = '../glove/glove.6B.100d.txt'\n",
    "EMBEDDING_DIM = 100\n",
    "EVAL_SPLIT = 0.2 \n",
    "#\n",
    "path='models/baseline_biderec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#open SQuAD-dataset and extract the relevant data from the json-file\n",
    "#to a easier readable/accessible dictionary\n",
    "with open('SQuAD/train-v2.0.json') as file:\n",
    "    train=json.load(file)\n",
    "train_context=[]\n",
    "train_question=[]\n",
    "train_answer=[]\n",
    "train_new={'context':train_context,'question':train_question,'answer':train_answer}\n",
    "for j,data in enumerate(train['data']):\n",
    "    for i,paragraph in enumerate(data['paragraphs']):\n",
    "        context=paragraph['context']\n",
    "        for qas in paragraph['qas']:\n",
    "            #create a dataset with only the answerable questions\n",
    "            if (qas['is_impossible']==False):\n",
    "                train_new['context'].append(context)\n",
    "                train_new['question'].append(qas['question'])\n",
    "                train_new['answer'].append(qas['answers'][0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concatenate the data in one vector for preprocessing\n",
    "train_all=[]\n",
    "for line in train_new['context']:\n",
    "    train_all.append(line)\n",
    "for line in train_new['question']:\n",
    "    train_all.append(line)\n",
    "for line in train_new['answer']:\n",
    "    train_all.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(91925,)\n"
     ]
    }
   ],
   "source": [
    "vocab = set()\n",
    "for text in train_all:\n",
    "    vocab |= set(text_to_word_sequence(text))\n",
    "vocab = sorted(vocab)\n",
    "vocab_size = len(vocab) + 1\n",
    "print(np.shape(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 91925 unique tokens.\n",
      "Shape of context tensor: (86821, 675)\n",
      "Shape of question tensor: (86821, 40)\n",
      "Shape of answer tensor: (86821, 43)\n"
     ]
    }
   ],
   "source": [
    "#prepare the data to use as input of the rnn\n",
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(train_all)\n",
    "context_sequences = tokenizer.texts_to_sequences(train_new['context'])\n",
    "question_sequences = tokenizer.texts_to_sequences(train_new['question'])\n",
    "answer_sequences = tokenizer.texts_to_sequences(train_new['answer'])\n",
    "\n",
    "max_len_context=max(map(len,context_sequences))\n",
    "max_len_question=max(map(len,question_sequences))\n",
    "max_len_answer=max(map(len,answer_sequences))\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "context = pad_sequences(context_sequences, maxlen=max_len_context)\n",
    "question = pad_sequences(question_sequences, maxlen=max_len_question)\n",
    "answer = pad_sequences(answer_sequences, maxlen=max_len_answer)\n",
    "\n",
    "print('Shape of context tensor:', context.shape)\n",
    "print('Shape of question tensor:', question.shape)\n",
    "print('Shape of answer tensor:', answer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into a training set and an evaluation set\n",
    "indices = np.arange(context.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "context = context[indices]\n",
    "question = question[indices]\n",
    "answer = answer[indices]\n",
    "num_eval_samples = int(EVAL_SPLIT * context.shape[0])\n",
    "\n",
    "x_train_context = context[:-num_eval_samples]\n",
    "x_train_question = question[:-num_eval_samples]\n",
    "y_train_answer = answer[:-num_eval_samples]\n",
    "\n",
    "x_eval_context = context[-num_eval_samples:]\n",
    "x_eval_question = question[-num_eval_samples:]\n",
    "y_eval_answer = answer[-num_eval_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#FIX_ME: add glove download\n",
    "# https://nlp.stanford.edu/projects/glove/\n",
    "#get glove embeddings\n",
    "embeddings_index = {}\n",
    "f = open(GLOVE_DIR)#os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract the glove-embedding to a matrix\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create non-trainable embedding layers\n",
    "# for the context and the question each\n",
    "context_embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_len_context,\n",
    "                            trainable=False,\n",
    "                            name='context_embedding')\n",
    "question_embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=max_len_question,\n",
    "                            trainable=False,\n",
    "                            name='question_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "successfully built the model\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Context_input (InputLayer)      (None, 675)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Question_input (InputLayer)     (None, 40)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "context_embedding (Embedding)   (None, 675, 100)     9192600     Context_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "question_embedding (Embedding)  (None, 40, 100)      9192600     Question_input[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_31 (Bidirectional (None, 675, 200)     160800      context_embedding[2][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_35 (Bidirectional (None, 40, 200)      160800      question_embedding[2][0]         \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_32 (Bidirectional (None, 675, 200)     240800      bidirectional_31[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_36 (Bidirectional (None, 40, 200)      240800      bidirectional_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_33 (Bidirectional (None, 675, 200)     240800      bidirectional_32[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_37 (Bidirectional (None, 40, 200)      240800      bidirectional_36[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_34 (Bidirectional (None, 200)          240800      bidirectional_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_38 (Bidirectional (None, 200)          240800      bidirectional_37[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, 400)          0           bidirectional_34[0][0]           \n",
      "                                                                 bidirectional_38[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 43)           17243       concatenate_9[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 20,168,843\n",
      "Trainable params: 1,783,643\n",
      "Non-trainable params: 18,385,200\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "\n",
    "context_layer = layers.Input(shape=(max_len_context,), dtype='int32',name='Context_input')\n",
    "encoded_context = context_embedding_layer(context_layer)\n",
    "encoded_context = Bidirectional(LSTM(SENT_HIDDEN_SIZE,return_sequences=True))(encoded_context)\n",
    "encoded_context = Bidirectional(LSTM(SENT_HIDDEN_SIZE,return_sequences=True))(encoded_context)\n",
    "encoded_context = Bidirectional(LSTM(SENT_HIDDEN_SIZE,return_sequences=True))(encoded_context)\n",
    "encoded_context = Bidirectional(LSTM(SENT_HIDDEN_SIZE))(encoded_context)\n",
    "\n",
    "question_layer = layers.Input(shape=(max_len_question,), dtype='int32',name='Question_input')\n",
    "encoded_question = question_embedding_layer(question_layer)\n",
    "encoded_question = Bidirectional(LSTM(QUERY_HIDDEN_SIZE,return_sequences=True))(encoded_question)\n",
    "encoded_question = Bidirectional(LSTM(QUERY_HIDDEN_SIZE,return_sequences=True))(encoded_question)\n",
    "encoded_question = Bidirectional(LSTM(QUERY_HIDDEN_SIZE,return_sequences=True))(encoded_question)\n",
    "encoded_question = Bidirectional(LSTM(QUERY_HIDDEN_SIZE))(encoded_question)\n",
    "\n",
    "merged = layers.concatenate([encoded_context, encoded_question])\n",
    "\n",
    "# bidirec = Bidirectional(LSTM(400))\n",
    "\n",
    "preds = layers.Dense(max_len_answer, activation='softmax')(merged) #dimensions of dense layer have to to the same as the answer dimensions\n",
    "\n",
    "model = Model([context_layer, question_layer], preds)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "print('successfully built the model')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "<class 'tensorflow.python.framework.ops.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# print('Build model...')\n",
    "# # from keras.layers import Merge\n",
    "\n",
    "# context_layer = layers.Input(shape=(max_len_context,), dtype='int32',name='Context_input')\n",
    "# encoded_context = context_embedding_layer(context_layer)\n",
    "# encoded_context = Bidirectional(LSTM(SENT_HIDDEN_SIZE))(encoded_context)\n",
    "\n",
    "# question_layer = layers.Input(shape=(max_len_question,), dtype='int32',name='Question_input')\n",
    "# encoded_question = question_embedding_layer(question_layer)\n",
    "# encoded_question = Bidirectional(LSTM(QUERY_HIDDEN_SIZE,return_sequences=True))(encoded_question)\n",
    "# encoded_question = Bidirectional(LSTM(QUERY_HIDDEN_SIZE))(encoded_question)\n",
    "\n",
    "# merged = layers.concatenate([encoded_context, encoded_question])\n",
    "# print(type(merged))\n",
    "\n",
    "# # preds = layers.Dense(max_len_answer, activation='softmax')(merged) #dimensions of dense layer have to to the same as the answer dimensions\n",
    "\n",
    "# # model = Model([context_layer, question_layer], preds)\n",
    "# # model.compile(optimizer='adam',\n",
    "# #               loss='categorical_crossentropy',\n",
    "# #               metrics=['accuracy'])\n",
    "# # print('successfully built the model')\n",
    "# # print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"556pt\" viewBox=\"0.00 0.00 590.00 556.00\" width=\"590pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 552)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-552 586,-552 586,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 140446008973688 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>140446008973688</title>\n",
       "<polygon fill=\"none\" points=\"60.5,-511.5 60.5,-547.5 221.5,-547.5 221.5,-511.5 60.5,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-525.8\">Context_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140446127680704 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>140446127680704</title>\n",
       "<polygon fill=\"none\" points=\"44,-438.5 44,-474.5 238,-474.5 238,-438.5 44,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-452.8\">context_embedding: Embedding</text>\n",
       "</g>\n",
       "<!-- 140446008973688&#45;&gt;140446127680704 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>140446008973688-&gt;140446127680704</title>\n",
       "<path d=\"M141,-511.4551C141,-503.3828 141,-493.6764 141,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"144.5001,-484.5903 141,-474.5904 137.5001,-484.5904 144.5001,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140446000163864 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>140446000163864</title>\n",
       "<polygon fill=\"none\" points=\"357.5,-511.5 357.5,-547.5 524.5,-547.5 524.5,-511.5 357.5,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"441\" y=\"-525.8\">Question_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 140446127680872 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>140446127680872</title>\n",
       "<polygon fill=\"none\" points=\"341,-438.5 341,-474.5 541,-474.5 541,-438.5 341,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"441\" y=\"-452.8\">question_embedding: Embedding</text>\n",
       "</g>\n",
       "<!-- 140446000163864&#45;&gt;140446127680872 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>140446000163864-&gt;140446127680872</title>\n",
       "<path d=\"M441,-511.4551C441,-503.3828 441,-493.6764 441,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"444.5001,-484.5903 441,-474.5904 437.5001,-484.5904 444.5001,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140446008974304 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>140446008974304</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 282,-401.5 282,-365.5 0,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-379.8\">bidirectional_31(lstm_32): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 140446127680704&#45;&gt;140446008974304 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>140446127680704-&gt;140446008974304</title>\n",
       "<path d=\"M141,-438.4551C141,-430.3828 141,-420.6764 141,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"144.5001,-411.5903 141,-401.5904 137.5001,-411.5904 144.5001,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140445992684792 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>140445992684792</title>\n",
       "<polygon fill=\"none\" points=\"300,-365.5 300,-401.5 582,-401.5 582,-365.5 300,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"441\" y=\"-379.8\">bidirectional_35(lstm_36): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 140446127680872&#45;&gt;140445992684792 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>140446127680872-&gt;140445992684792</title>\n",
       "<path d=\"M441,-438.4551C441,-430.3828 441,-420.6764 441,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"444.5001,-411.5903 441,-401.5904 437.5001,-411.5904 444.5001,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140446005331280 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>140446005331280</title>\n",
       "<polygon fill=\"none\" points=\"0,-292.5 0,-328.5 282,-328.5 282,-292.5 0,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-306.8\">bidirectional_32(lstm_33): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 140446008974304&#45;&gt;140446005331280 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>140446008974304-&gt;140446005331280</title>\n",
       "<path d=\"M141,-365.4551C141,-357.3828 141,-347.6764 141,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"144.5001,-338.5903 141,-328.5904 137.5001,-338.5904 144.5001,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140445988045768 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>140445988045768</title>\n",
       "<polygon fill=\"none\" points=\"300,-292.5 300,-328.5 582,-328.5 582,-292.5 300,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"441\" y=\"-306.8\">bidirectional_36(lstm_37): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 140445992684792&#45;&gt;140445988045768 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>140445992684792-&gt;140445988045768</title>\n",
       "<path d=\"M441,-365.4551C441,-357.3828 441,-347.6764 441,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"444.5001,-338.5903 441,-328.5904 437.5001,-338.5904 444.5001,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140446000400648 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>140446000400648</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 282,-255.5 282,-219.5 0,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-233.8\">bidirectional_33(lstm_34): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 140446005331280&#45;&gt;140446000400648 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>140446005331280-&gt;140446000400648</title>\n",
       "<path d=\"M141,-292.4551C141,-284.3828 141,-274.6764 141,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"144.5001,-265.5903 141,-255.5904 137.5001,-265.5904 144.5001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140445983092520 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>140445983092520</title>\n",
       "<polygon fill=\"none\" points=\"300,-219.5 300,-255.5 582,-255.5 582,-219.5 300,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"441\" y=\"-233.8\">bidirectional_37(lstm_38): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 140445988045768&#45;&gt;140445983092520 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>140445988045768-&gt;140445983092520</title>\n",
       "<path d=\"M441,-292.4551C441,-284.3828 441,-274.6764 441,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"444.5001,-265.5903 441,-255.5904 437.5001,-265.5904 444.5001,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140445996708640 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>140445996708640</title>\n",
       "<polygon fill=\"none\" points=\"0,-146.5 0,-182.5 282,-182.5 282,-146.5 0,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"141\" y=\"-160.8\">bidirectional_34(lstm_35): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 140446000400648&#45;&gt;140445996708640 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>140446000400648-&gt;140445996708640</title>\n",
       "<path d=\"M141,-219.4551C141,-211.3828 141,-201.6764 141,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"144.5001,-192.5903 141,-182.5904 137.5001,-192.5904 144.5001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140445978767256 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>140445978767256</title>\n",
       "<polygon fill=\"none\" points=\"300,-146.5 300,-182.5 582,-182.5 582,-146.5 300,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"441\" y=\"-160.8\">bidirectional_38(lstm_39): Bidirectional(LSTM)</text>\n",
       "</g>\n",
       "<!-- 140445983092520&#45;&gt;140445978767256 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>140445983092520-&gt;140445978767256</title>\n",
       "<path d=\"M441,-219.4551C441,-211.3828 441,-201.6764 441,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"444.5001,-192.5903 441,-182.5904 437.5001,-192.5904 444.5001,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140445982899896 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>140445982899896</title>\n",
       "<polygon fill=\"none\" points=\"207,-73.5 207,-109.5 375,-109.5 375,-73.5 207,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"291\" y=\"-87.8\">concatenate_9: Concatenate</text>\n",
       "</g>\n",
       "<!-- 140445996708640&#45;&gt;140445982899896 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>140445996708640-&gt;140445982899896</title>\n",
       "<path d=\"M178.0787,-146.4551C198.1811,-136.6719 223.2159,-124.4883 244.6015,-114.0806\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"246.3679,-117.1135 253.828,-109.5904 243.3047,-110.8193 246.3679,-117.1135\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140445978767256&#45;&gt;140445982899896 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>140445978767256-&gt;140445982899896</title>\n",
       "<path d=\"M403.9213,-146.4551C383.8189,-136.6719 358.7841,-124.4883 337.3985,-114.0806\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"338.6953,-110.8193 328.172,-109.5904 335.6321,-117.1135 338.6953,-110.8193\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 140445975260520 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>140445975260520</title>\n",
       "<polygon fill=\"none\" points=\"240,-.5 240,-36.5 342,-36.5 342,-.5 240,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"291\" y=\"-14.8\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 140445982899896&#45;&gt;140445975260520 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>140445982899896-&gt;140445975260520</title>\n",
       "<path d=\"M291,-73.4551C291,-65.3828 291,-55.6764 291,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"294.5001,-46.5903 291,-36.5904 287.5001,-46.5904 294.5001,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Training')\n",
    "# model.fit([x_train_context, x_train_question], y_train_answer,\n",
    "#           batch_size=BATCH_SIZE,\n",
    "#           epochs=EPOCHS,\n",
    "#           validation_split=0.05)\n",
    "\n",
    "# print('Evaluation')\n",
    "# loss, acc = model.evaluate([x_eval_context, x_eval_question], y_eval_answer,\n",
    "#                            batch_size=BATCH_SIZE)\n",
    "# print('Test loss / test accuracy = {:.4f} / {:.4f}'.format(loss, acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('save model')\n",
    "plot_model(model, to_file=path+'/model.png')\n",
    "model.save_weights('models/baseline/baseline_model.h5') #save weights\n",
    "model_json = model.to_json()\n",
    "with open(\"models/baseline/baseline_model.json\",'w') as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
